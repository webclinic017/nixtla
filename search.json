[
  {
    "objectID": "distributed.timegpt.html",
    "href": "distributed.timegpt.html",
    "title": "Spark",
    "section": "",
    "text": "Give us a ⭐ on Github"
  },
  {
    "objectID": "distributed.timegpt.html#ray",
    "href": "distributed.timegpt.html#ray",
    "title": "Spark",
    "section": "Ray",
    "text": "Ray"
  },
  {
    "objectID": "timegpt.html",
    "href": "timegpt.html",
    "title": "TimeGPT",
    "section": "",
    "text": "Nixtla’s TimeGPT is a generative pre-trained model trained to forecast time series data. The inputs to TimeGPT are time series data, and the model generates forecast outputs based on these. The input involves providing the historical data and potentially defining parameters such as the forecast horizon. TimeGPT can be used across a plethora of tasks including demand forecasting, anomaly detection, financial forecasting, and more.\nThe TimeGPT model “reads” time series data much like the way humans read a sentence – from left to right. It looks at a chunk of past data, which we can think of as “tokens”, and predicts what comes next. This prediction is based on patterns the model identifies in past data, much like how a human would predict the end of a sentence based on the beginning.\nThe TimeGPT API provides an interface to this powerful model, allowing users to leverage its forecasting capabilities to predict future events based on past data. With this API, users can not only forecast future events but also delve into various time series-related tasks, such as what-if scenarios, anomaly detection, and more.\n\n\n\nfigure\nGive us a ⭐ on Github"
  },
  {
    "objectID": "timegpt.html#introduction",
    "href": "timegpt.html#introduction",
    "title": "TimeGPT",
    "section": "",
    "text": "Nixtla’s TimeGPT is a generative pre-trained model trained to forecast time series data. The inputs to TimeGPT are time series data, and the model generates forecast outputs based on these. The input involves providing the historical data and potentially defining parameters such as the forecast horizon. TimeGPT can be used across a plethora of tasks including demand forecasting, anomaly detection, financial forecasting, and more.\nThe TimeGPT model “reads” time series data much like the way humans read a sentence – from left to right. It looks at a chunk of past data, which we can think of as “tokens”, and predicts what comes next. This prediction is based on patterns the model identifies in past data, much like how a human would predict the end of a sentence based on the beginning.\nThe TimeGPT API provides an interface to this powerful model, allowing users to leverage its forecasting capabilities to predict future events based on past data. With this API, users can not only forecast future events but also delve into various time series-related tasks, such as what-if scenarios, anomaly detection, and more.\n\n\n\nfigure"
  },
  {
    "objectID": "timegpt.html#usage",
    "href": "timegpt.html#usage",
    "title": "TimeGPT",
    "section": "Usage",
    "text": "Usage\n\n\nTimeGPT\n\n TimeGPT (token:str, environment:Optional[str]=None)\n\nConstructs all the necessary attributes for the TimeGPT object.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntoken\nstr\n\nThe authorization token to interact with the TimeGPT API.\n\n\nenvironment\nOptional\nNone\nCustom environment. Pass only if provided.\n\n\n\nYou can instantiate the TimeGPT class providing your credentials.\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nYou can test the validate of your token calling the validate_token method:\n\n\nTimeGPT.validate_token\n\n TimeGPT.validate_token (log:bool=True)\n\nReturns True if your token is valid.\n\ntimegpt.validate_token()\n\nINFO:__main__:Happy Forecasting! :), If you have questions or need support, please email ops@nixtla.io\n\n\nTrue\n\n\n\n\n\nForecast\n\n\nTimeGPT.forecast\n\n TimeGPT.forecast (df:pandas.core.frame.DataFrame, h:int,\n                   freq:Optional[str]=None, id_col:str='unique_id',\n                   time_col:str='ds', target_col:str='y',\n                   X_df:Optional[pandas.core.frame.DataFrame]=None,\n                   level:Optional[List[Union[int,float]]]=None,\n                   finetune_steps:int=0, clean_ex_first:bool=True,\n                   validate_token:bool=False, add_history:bool=False,\n                   date_features:Union[bool,List[str]]=False,\n                   date_features_to_one_hot:Union[bool,List[str]]=True,\n                   num_partitions:Optional[int]=None)\n\nForecast your time series using TimeGPT.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nThe DataFrame on which the function will operate. Expected to contain at least the following columns:- time_col: Column name in df that contains the time indices of the time series. This is typically a datetime column with regular intervals, e.g., hourly, daily, monthly data points.- target_col: Column name in df that contains the target variable of the time series, i.e., the variable we  wish to predict or analyze.Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:- id_col: Column name in df that identifies unique time series. Each unique value in this column corresponds to a unique time series.\n\n\nh\nint\n\nForecast horizon.\n\n\nfreq\nOptional\nNone\nFrequency of the data. By default, the freq will be inferred automatically.See pandas’ available frequencies.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nX_df\nOptional\nNone\nDataFrame with [unique_id, ds] columns and df’s future exogenous.\n\n\nlevel\nOptional\nNone\nConfidence levels between 0 and 100 for prediction intervals.\n\n\nfinetune_steps\nint\n0\nNumber of steps used to finetune TimeGPT in thenew data.\n\n\nclean_ex_first\nbool\nTrue\nClean exogenous signal before making forecastsusing TimeGPT.\n\n\nvalidate_token\nbool\nFalse\nIf True, validates token before sending requests.\n\n\nadd_history\nbool\nFalse\nReturn fitted values of the model.\n\n\ndate_features\nUnion\nFalse\nFeatures computed from the dates. Can be pandas date attributes or functions that will take the dates as input.If True automatically adds most used date features for the frequency of df.\n\n\ndate_features_to_one_hot\nUnion\nTrue\nApply one-hot encoding to these date features.If date_features=True, then all date features areone-hot encoded by default.\n\n\nnum_partitions\nOptional\nNone\nNumber of partitions to use.Only used in distributed environments (spark, ray, dask).If None, the number of partitions will be equalto the available parallel resources.\n\n\nReturns\npandas.DataFrame\n\nDataFrame with TimeGPT forecasts for point predictions and probabilisticpredictions (if level is not None).\n\n\n\nNow you can start to make forecasts! Let’s import an example:\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/air_passengers.csv')\ndf.head()\n\n\n\n\n\n\n\n\ntimestamp\nvalue\n\n\n\n\n0\n1949-01-01\n112\n\n\n1\n1949-02-01\n118\n\n\n2\n1949-03-01\n132\n\n\n3\n1949-04-01\n129\n\n\n4\n1949-05-01\n121\n\n\n\n\n\n\n\nLet’s plot this series\n\ndf.set_index('timestamp').plot(figsize=(20, 10))\n\n&lt;Axes: xlabel='timestamp'&gt;\n\n\n\n\n\nNow we can forecast this dataset. We observe that this dataset has monthly frequency. We have to pass the right pandas frequency to TimeGPT to have the right forecasts. In this case ‘MS’. Let’s forecast the next 12 observations. In this case we also have to define:\n\ntime_col: Column that identifies the datestamp column.\ntarget_col: The variable that we want to forecast.\n\n\ntimegpt_fcst_df = timegpt.forecast(df=df, h=12, time_col='timestamp', target_col='value')\ntimegpt_fcst_df.head()\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\n\n\n\n\n\n\n\n\n\ntimestamp\nTimeGPT\n\n\n\n\n0\n1961-01-01\n437.837921\n\n\n1\n1961-02-01\n426.062714\n\n\n2\n1961-03-01\n463.116547\n\n\n3\n1961-04-01\n478.244507\n\n\n4\n1961-05-01\n505.646484\n\n\n\n\n\n\n\n\npd.concat([df, timegpt_fcst_df]).set_index('timestamp').plot(figsize=(20, 10))\n\n&lt;Axes: xlabel='timestamp'&gt;\n\n\n\n\n\nYou can also produce a larger forecast horizon:\n\ntimegpt_fcst_df = timegpt.forecast(df=df, h=36, time_col='timestamp', target_col='value')\ntimegpt_fcst_df.head()\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\nWARNING:__main__:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n\n\n\n\n\n\n\ntimestamp\nTimeGPT\n\n\n\n\n0\n1961-01-01\n437.837921\n\n\n1\n1961-02-01\n426.062714\n\n\n2\n1961-03-01\n463.116547\n\n\n3\n1961-04-01\n478.244507\n\n\n4\n1961-05-01\n505.646484\n\n\n\n\n\n\n\n\npd.concat([df, timegpt_fcst_df]).set_index('timestamp').plot(figsize=(20, 10))\n\n&lt;Axes: xlabel='timestamp'&gt;\n\n\n\n\n\nOr a shorter one:\n\ntimegpt_fcst_df = timegpt.forecast(df=df, h=6, time_col='timestamp', target_col='value')\npd.concat([df, timegpt_fcst_df]).set_index('timestamp').plot(figsize=(20, 10))\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\n\n\n&lt;Axes: xlabel='timestamp'&gt;\n\n\n\n\n\n\n\n\nAnomaly Detection\nAnomaly detection in time series data plays a pivotal role in numerous sectors including finance, healthcare, security, and infrastructure. In essence, time series data represents a sequence of data points indexed (or listed or graphed) in time order, often with equal intervals. As systems and processes become increasingly digitized and interconnected, the need to monitor and ensure their normal behavior grows proportionally. Detecting anomalies can indicate potential problems, malfunctions, or even malicious activities. By promptly identifying these deviations from the expected pattern, organizations can take preemptive measures, optimize processes, or protect resources. TimeGPT includes the detect_anomalies method to detect anomalies automatically.\n\n\nTimeGPT.detect_anomalies\n\n TimeGPT.detect_anomalies (df:pandas.core.frame.DataFrame,\n                           freq:Optional[str]=None,\n                           id_col:str='unique_id', time_col:str='ds',\n                           target_col:str='y', level:Union[int,float]=99,\n                           validate_token:bool=False)\n\nDetect anomalies in your time series using TimeGPT.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nThe DataFrame on which the function will operate. Expected to contain at least the following columns:- time_col: Column name in df that contains the time indices of the time series. This is typically a datetime column with regular intervals, e.g., hourly, daily, monthly data points.- target_col: Column name in df that contains the target variable of the time series, i.e., the variable we  wish to predict or analyze.Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:- id_col: Column name in df that identifies unique time series. Each unique value in this column corresponds to a unique time series.\n\n\nfreq\nOptional\nNone\nFrequency of the data. By default, the freq will be inferred automatically.See pandas’ available frequencies.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nlevel\nUnion\n99\nConfidence level between 0 and 100 for detecting the anomalies.\n\n\nvalidate_token\nbool\nFalse\n\n\n\nReturns\npandas.DataFrame\n\nDataFrame with anomalies flagged with 1 detected by TimeGPT.\n\n\n\nThe detect_anomalies method is designed to process a dataframe containing series and subsequently label each observation based on its anomalous nature. When fed a dataframe, the method evaluates each observation against its context within the series, using statistical measures to determine its likelihood of being an anomaly. By default, the method identifies anomalies based on a 99 percent prediction interval. Observations that fall outside this interval are considered anomalies. The resultant dataframe will feature an added label, “anomaly”, that is set to 1 for anomalous observations and 0 otherwise.\n\npm_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/peyton_manning.csv')\ntimegpt_anomalies_df = timegpt.detect_anomalies(pm_df, time_col='timestamp', target_col='value', freq='D')\ntimegpt_anomalies_df.head()\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Anomaly Detector Endpoint...\n\n\n\n\n\n\n\n\n\ntimestamp\nanomaly\n\n\n\n\n0\n2008-01-10\n0\n\n\n1\n2008-01-11\n0\n\n\n2\n2008-01-12\n0\n\n\n3\n2008-01-13\n0\n\n\n4\n2008-01-14\n0\n\n\n\n\n\n\n\n\ntimegpt_anomalies_df = pm_df.merge(timegpt_anomalies_df, how='inner')\ntimegpt_anomalies_df['timestamp'] = pd.to_datetime(timegpt_anomalies_df['timestamp'])\nax = timegpt_anomalies_df.set_index('timestamp')['value'].plot.line(figsize=(10,6))\n# Highlight anomalies with red color\nanomalies = timegpt_anomalies_df.query('anomaly == 1')\nanomalies.plot.scatter(x='timestamp', y='value', c='red', marker='o', label='Anomalies', ax=ax)\nax.legend()\n\n&lt;matplotlib.legend.Legend&gt;\n\n\n\n\n\nWhile the default behavior of the detect_anomalies method is to operate using a 99 percent prediction interval, users have the flexibility to adjust this threshold to their requirements. This is achieved by modifying the level argument. Decreasing the value of the level argument will result in a broader prediction interval, subsequently identifying more observations as anomalies. See the next example.\n\ntimegpt_anomalies_df = timegpt.detect_anomalies(pm_df, time_col='timestamp', target_col='value', freq='D', level=90)\ntimegpt_anomalies_df = pm_df.merge(timegpt_anomalies_df, how='inner')\ntimegpt_anomalies_df['timestamp'] = pd.to_datetime(timegpt_anomalies_df['timestamp'])\nax = timegpt_anomalies_df.set_index('timestamp')['value'].plot.line(figsize=(10,6))\n# Highlight anomalies with red color\nanomalies = timegpt_anomalies_df.query('anomaly == 1')\nanomalies.plot.scatter(x='timestamp', y='value', c='red', marker='o', label='Anomalies', ax=ax)\nax.legend()\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Anomaly Detector Endpoint...\n\n\n&lt;matplotlib.legend.Legend&gt;\n\n\n\n\n\nConversely, increasing the value will tighten the prediction interval, detecting fewer anomalies. This customization allows users to calibrate the sensitivity of the method to align with their specific use case, ensuring the most relevant and actionable insights are derived from the data.\n\ntimegpt_anomalies_df = timegpt.detect_anomalies(pm_df, time_col='timestamp', target_col='value', freq='D', level=99.99)\ntimegpt_anomalies_df = pm_df.merge(timegpt_anomalies_df, how='inner')\ntimegpt_anomalies_df['timestamp'] = pd.to_datetime(timegpt_anomalies_df['timestamp'])\nax = timegpt_anomalies_df.set_index('timestamp')['value'].plot.line(figsize=(10,6))\n# Highlight anomalies with red color\nanomalies = timegpt_anomalies_df.query('anomaly == 1')\nanomalies.plot.scatter(x='timestamp', y='value', c='red', marker='o', label='Anomalies', ax=ax)\nax.legend()\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Anomaly Detector Endpoint...\n\n\n&lt;matplotlib.legend.Legend&gt;\n\n\n\n\n\n\n\n\nHistorical forecast\nOur time series model offers a powerful feature that allows users to retrieve historical forecasts alongside the prospective predictions. This functionality is accessible through the forecast method by setting the add_history=True argument.\n\ntimegpt_fcst_with_history_df = timegpt.forecast(\n    df=df, h=12, time_col='timestamp', target_col='value',\n    add_history=True,\n)\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\nINFO:__main__:Calling Historical Forecast Endpoint...\n\n\nWhen add_history is set to True, the output DataFrame will include not only the future forecasts determined by the h argument, but also the historical predictions. This consolidated view of past and future predictions can be invaluable for understanding the model’s behavior and for evaluating its performance over time.\n\ntimegpt_fcst_with_history_df.head()\n\n\n\n\n\n\n\n\ntimestamp\nTimeGPT\n\n\n\n\n0\n1951-01-01\n135.483673\n\n\n1\n1951-02-01\n144.442398\n\n\n2\n1951-03-01\n157.191910\n\n\n3\n1951-04-01\n148.769363\n\n\n4\n1951-05-01\n140.472946\n\n\n\n\n\n\n\nLet’s plot the results.\n\ndf.merge(timegpt_fcst_with_history_df, how='outer').set_index('timestamp').plot(figsize=(20, 10))\n\n&lt;Axes: xlabel='timestamp'&gt;\n\n\n\n\n\nPlease note, however, that the initial values of the series are not included in these historical forecasts. This is because our model, TimeGPT, requires a certain number of initial observations to generate reliable forecasts. Therefore, while interpreting the output, it’s important to be aware that the first few observations serve as the basis for the model’s predictions and are not themselves predicted values.\n\n\nPrediction Intervals\nPrediction intervals provide a measure of the uncertainty in the forecasted values. In time series forecasting, a prediction interval gives an estimated range within which a future observation will fall, based on the level of confidence or uncertainty you set. This level of uncertainty is crucial for making informed decisions, risk assessments, and planning.\nFor instance, a 95% prediction interval means that 95 out of 100 times, the actual future value will fall within the estimated range. Therefore, a wider interval indicates greater uncertainty about the forecast, while a narrower interval suggests higher confidence.\nWhen using TimeGPT for time series forecasting, you have the option to set the level of prediction intervals according to your requirements. TimeGPT uses conformal prediction to calibrate the intervals.\nHere’s how you could do it:\n\ntimegpt_fcst_pred_int_df = timegpt.forecast(\n    df=df, h=12, level=[80, 90, 99.7], \n    time_col='timestamp', target_col='value',\n)\ntimegpt_fcst_pred_int_df.head()\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\n\n\n\n\n\n\n\n\n\ntimestamp\nTimeGPT\nTimeGPT-lo-99.7\nTimeGPT-lo-90\nTimeGPT-lo-80\nTimeGPT-hi-80\nTimeGPT-hi-90\nTimeGPT-hi-99.7\n\n\n\n\n0\n1961-01-01\n437.837921\n415.826453\n423.783707\n431.987061\n443.688782\n451.892136\n459.849389\n\n\n1\n1961-02-01\n426.062714\n402.833523\n407.694061\n412.704926\n439.420502\n444.431366\n449.291904\n\n\n2\n1961-03-01\n463.116547\n423.434062\n430.316862\n437.412534\n488.820560\n495.916231\n502.799032\n\n\n3\n1961-04-01\n478.244507\n444.885193\n446.776764\n448.726837\n507.762177\n509.712250\n511.603821\n\n\n4\n1961-05-01\n505.646484\n465.736694\n471.976787\n478.409872\n532.883096\n539.316182\n545.556275\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n\nhistory_with_fcst_df = pd.concat([df, timegpt_fcst_pred_int_df])\nax = history_with_fcst_df[['timestamp', 'value', 'TimeGPT']].set_index('timestamp').plot(figsize=(20, 10))\nfor level, alpha in zip([80, 90, 99.7], [0.4, 0.2, 0.1]):\n    plt.fill_between(\n        history_with_fcst_df['timestamp'], \n        history_with_fcst_df[f'TimeGPT-lo-{level}'], \n        history_with_fcst_df[f'TimeGPT-hi-{level}'], \n        color='orange', \n        alpha=alpha,\n        label=f'TimeGPT-level-{level}]'\n    )\nplt.legend()\nplt.show()\n\n\n\n\nIt’s essential to note that the choice of prediction interval level depends on your specific use case. For high-stakes predictions, you might want a wider interval to account for more uncertainty. For less critical forecasts, a narrower interval might be acceptable.\n\nHistorical Forecast\nYou can also compute prediction intervals for historical forecasts adding the add_history=True parameter as follows:\n\ntimegpt_fcst_pred_int_historical_df = timegpt.forecast(\n    df=df, h=12, level=[80, 90, 99.7], \n    time_col='timestamp', target_col='value',\n    add_history=True,\n)\ntimegpt_fcst_pred_int_historical_df.head()\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\nINFO:__main__:Calling Historical Forecast Endpoint...\n\n\n\n\n\n\n\n\n\ntimestamp\nTimeGPT\nTimeGPT-lo-80\nTimeGPT-lo-90\nTimeGPT-lo-99.7\nTimeGPT-hi-80\nTimeGPT-hi-90\nTimeGPT-hi-99.7\n\n\n\n\n0\n1951-01-01\n135.483673\n111.937768\n105.262831\n80.957520\n159.029579\n165.704516\n190.009826\n\n\n1\n1951-02-01\n144.442398\n120.896493\n114.221556\n89.916245\n167.988304\n174.663241\n198.968551\n\n\n2\n1951-03-01\n157.191910\n133.646004\n126.971067\n102.665757\n180.737815\n187.412752\n211.718063\n\n\n3\n1951-04-01\n148.769363\n125.223458\n118.548521\n94.243210\n172.315269\n178.990206\n203.295516\n\n\n4\n1951-05-01\n140.472946\n116.927041\n110.252104\n85.946793\n164.018852\n170.693789\n194.999099\n\n\n\n\n\n\n\n\nhistory_with_fcst_df = df.merge(timegpt_fcst_pred_int_historical_df, how='outer')\nax = history_with_fcst_df[['timestamp', 'value', 'TimeGPT']].set_index('timestamp').plot(figsize=(20, 10))\nfor level, alpha in zip([80, 90, 99.7], [0.4, 0.2, 0.1]):\n    plt.fill_between(\n        history_with_fcst_df['timestamp'], \n        history_with_fcst_df[f'TimeGPT-lo-{level}'], \n        history_with_fcst_df[f'TimeGPT-hi-{level}'], \n        color='orange', \n        alpha=alpha,\n        label=f'TimeGPT-level-{level}]'\n    )\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nFinetuning\nFine-tuning is a process of further training a pre-existing model (like TimeGPT) on a specific task or dataset. This allows you to leverage the general language understanding capabilities of the pre-trained model and adapt it to your specific use case.\nIn TimeGPT, you can use the finetune_steps argument to specify the number of additional training steps the model should undergo on your time series data. This helps in refining the model’s understanding and prediction of your data patterns.\nHere’s an example of how to fine-tune TimeGPT:\n\ntimegpt_fcst_finetune_df = timegpt.forecast(\n    df=df, h=12, finetune_steps=10,\n    time_col='timestamp', target_col='value',\n)\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\n\n\n\npd.concat([df, timegpt_fcst_finetune_df]).set_index('timestamp').plot(figsize=(20, 10))\n\n&lt;Axes: xlabel='timestamp'&gt;\n\n\n\n\n\nIn this code, finetune_steps: 10 means the model will go through 10 iterations of training on your time series data.\nKeep in mind that fine-tuning can be a bit of trial and error. You might need to adjust the number of finetune_steps based on your specific needs and the complexity of your data. It’s recommended to monitor the model’s performance during fine-tuning and adjust as needed. Be aware that more finetune_steps may lead to longer training times and could potentially lead to overfitting if not managed properly.\nRemember, fine-tuning is a powerful feature, but it should be used thoughtfully and carefully.\n\n\nMultiple Series\nTimeGPT provides a robust solution for multi-series forecasting, which involves analyzing multiple data series concurrently, rather than a single one. The tool can be fine-tuned using a broad collection of series, enabling you to tailor the model to suit your specific needs or tasks.\nThe following dataset contains prices of different electricity markets. Let see how can we forecast them.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short.csv')\ndf.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nBE\n2016-12-01 00:00:00\n72.00\n\n\n1\nBE\n2016-12-01 01:00:00\n65.80\n\n\n2\nBE\n2016-12-01 02:00:00\n59.99\n\n\n3\nBE\n2016-12-01 03:00:00\n50.69\n\n\n4\nBE\n2016-12-01 04:00:00\n52.58\n\n\n\n\n\n\n\nLet’s plot this series using StatsForecast:\n\nfrom statsforecast import StatsForecast as sf\n\n\nsf.plot(df, engine='matplotlib')\n\n\n\n\nWe just have to pass the dataframe to create forecasts for all the time series at once.\n\ntimegpt_fcst_multiseries_df = timegpt.forecast(df=df, h=24, level=[80, 90])\ntimegpt_fcst_multiseries_df.head()\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\n\n\n\n\n\n\n\n\n\nunique_id\nds\nTimeGPT\nTimeGPT-lo-90\nTimeGPT-lo-80\nTimeGPT-hi-80\nTimeGPT-hi-90\n\n\n\n\n0\nBE\n2016-12-31 00:00:00\n46.151176\n36.660478\n38.337019\n53.965334\n55.641875\n\n\n1\nBE\n2016-12-31 01:00:00\n42.426601\n31.602235\n33.976728\n50.876475\n53.250968\n\n\n2\nBE\n2016-12-31 02:00:00\n40.242889\n30.439970\n33.634985\n46.850794\n50.045809\n\n\n3\nBE\n2016-12-31 03:00:00\n38.265339\n26.841481\n31.022093\n45.508585\n49.689197\n\n\n4\nBE\n2016-12-31 04:00:00\n36.618801\n18.541384\n27.981346\n45.256256\n54.696218\n\n\n\n\n\n\n\n\nsf.plot(df, timegpt_fcst_multiseries_df, max_insample_length=365, level=[80, 90], engine='matplotlib')\n\n\n\n\n\nHistorical forecast\nYou can also compute prediction intervals for historical forecasts adding the add_history=True parameter as follows:\n\ntimegpt_fcst_multiseries_with_history_df = timegpt.forecast(df=df, h=24, level=[80, 90], add_history=True)\ntimegpt_fcst_multiseries_with_history_df.head()\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\nINFO:__main__:Calling Historical Forecast Endpoint...\n\n\n\n\n\n\n\n\n\nunique_id\nds\nTimeGPT\nTimeGPT-lo-80\nTimeGPT-lo-90\nTimeGPT-hi-80\nTimeGPT-hi-90\n\n\n\n\n0\nBE\n2016-12-06 00:00:00\n55.756325\n42.066469\n38.185585\n69.446180\n73.327064\n\n\n1\nBE\n2016-12-06 01:00:00\n52.820198\n39.130342\n35.249458\n66.510054\n70.390938\n\n\n2\nBE\n2016-12-06 02:00:00\n46.851070\n33.161215\n29.280331\n60.540926\n64.421810\n\n\n3\nBE\n2016-12-06 03:00:00\n50.640877\n36.951021\n33.070137\n64.330732\n68.211616\n\n\n4\nBE\n2016-12-06 04:00:00\n52.420403\n38.730547\n34.849663\n66.110258\n69.991142\n\n\n\n\n\n\n\n\nsf.plot(\n    df, \n    timegpt_fcst_multiseries_with_history_df.groupby('unique_id').tail(365 + 24), \n    max_insample_length=365, level=[80, 90], engine='matplotlib',\n)\n\n/Users/fedex/miniconda3/envs/nixtlats/lib/python3.10/site-packages/statsforecast/core.py:1527: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  forecasts_df[\"unique_id\"] = forecasts_df[\"unique_id\"].astype(\n\n\n\n\n\n\n\n\nExogenous variables\nExogenous variables or external factors are crucial in time series forecasting as they provide additional information that might influence the prediction. These variables could include holiday markers, marketing spending, weather data, or any other external data that correlate with the time series data you are forecasting.\nFor example, if you’re forecasting ice cream sales, temperature data could serve as a useful exogenous variable. On hotter days, ice cream sales may increase.\nTo incorporate exogenous variables in TimeGPT, you’ll need to pair each point in your time series data with the corresponding external data.\nLet’s see an example.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-with-ex-vars.csv')\ndf.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nExogenous1\nExogenous2\nday_0\nday_1\nday_2\nday_3\nday_4\nday_5\nday_6\n\n\n\n\n0\nBE\n2016-12-01 00:00:00\n72.00\n61507.0\n71066.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n1\nBE\n2016-12-01 01:00:00\n65.80\n59528.0\n67311.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\nBE\n2016-12-01 02:00:00\n59.99\n58812.0\n67470.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n3\nBE\n2016-12-01 03:00:00\n50.69\n57676.0\n64529.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n4\nBE\n2016-12-01 04:00:00\n52.58\n56804.0\n62773.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\nTo produce forecasts we have to add the future values of the exogenous variables. Let’s read this dataset. In this case we want to predict 24 steps ahead, therefore each unique id will have 24 observations.\n\nfuture_ex_vars_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-future-ex-vars.csv')\nfuture_ex_vars_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nExogenous1\nExogenous2\nday_0\nday_1\nday_2\nday_3\nday_4\nday_5\nday_6\n\n\n\n\n0\nBE\n2016-12-31 00:00:00\n64108.0\n70318.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\nBE\n2016-12-31 01:00:00\n62492.0\n67898.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\nBE\n2016-12-31 02:00:00\n61571.0\n68379.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\nBE\n2016-12-31 03:00:00\n60381.0\n64972.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\nBE\n2016-12-31 04:00:00\n60298.0\n62900.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n\n\n\n\n\nLet’s call the forecast method, adding this information:\n\ntimegpt_fcst_ex_vars_df = timegpt.forecast(df=df, X_df=future_ex_vars_df, h=24, level=[80, 90])\ntimegpt_fcst_ex_vars_df.head()\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\n\n\n\n\n\n\n\n\n\nunique_id\nds\nTimeGPT\nTimeGPT-lo-90\nTimeGPT-lo-80\nTimeGPT-hi-80\nTimeGPT-hi-90\n\n\n\n\n0\nBE\n2016-12-31 00:00:00\n38.861762\n33.821073\n34.368669\n43.354854\n43.902450\n\n\n1\nBE\n2016-12-31 01:00:00\n35.382102\n30.014594\n31.493322\n39.270882\n40.749610\n\n\n2\nBE\n2016-12-31 02:00:00\n33.811425\n26.658821\n28.543087\n39.079764\n40.964029\n\n\n3\nBE\n2016-12-31 03:00:00\n31.707475\n24.896205\n26.818795\n36.596155\n38.518745\n\n\n4\nBE\n2016-12-31 04:00:00\n30.316475\n21.125143\n24.432148\n36.200801\n39.507807\n\n\n\n\n\n\n\n\nsf.plot(df[['unique_id', 'ds', 'y']], timegpt_fcst_ex_vars_df, max_insample_length=365, level=[80, 90], engine='matplotlib')\n\n/Users/fedex/miniconda3/envs/nixtlats/lib/python3.10/site-packages/statsforecast/core.py:1514: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"unique_id\"] = df[\"unique_id\"].astype(uid_dtype)\n\n\n\n\n\n\ndf['ds'] = pd.to_datetime(df['ds'])\n\n\ndf.set_index('ds').groupby('unique_id').resample('H').bfill().drop(columns='unique_id').reset_index()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nExogenous1\nExogenous2\nday_0\nday_1\nday_2\nday_3\nday_4\nday_5\nday_6\n\n\n\n\n0\nBE\n2016-12-01 00:00:00\n72.000000\n61507.0\n71066.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n1\nBE\n2016-12-01 01:00:00\n65.800000\n59528.0\n67311.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\nBE\n2016-12-01 02:00:00\n59.990000\n58812.0\n67470.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n3\nBE\n2016-12-01 03:00:00\n50.690000\n57676.0\n64529.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n4\nBE\n2016-12-01 04:00:00\n52.580000\n56804.0\n62773.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3595\nPJM\n2018-12-23 19:00:00\n32.461970\n98288.0\n11711.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n3596\nPJM\n2018-12-23 20:00:00\n32.052179\n97194.0\n11637.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n3597\nPJM\n2018-12-23 21:00:00\n27.632347\n94319.0\n11433.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n3598\nPJM\n2018-12-23 22:00:00\n24.746053\n90106.0\n11108.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n3599\nPJM\n2018-12-23 23:00:00\n23.333499\n85547.0\n10581.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n\n\n3600 rows × 12 columns\n\n\n\nWe also can get the importance of the features.\n\ntimegpt.weights_x.plot.barh(x='features', y='weights')\n\n&lt;Axes: ylabel='features'&gt;\n\n\n\n\n\n\n\nForecasting Time Series with Irregular Timestamps\nWhen working with time series data, the frequency of the timestamps is a crucial factor that can significantly impact the forecasting results. Regular frequencies like daily, weekly, or monthly are straightforward to handle. However, irregular frequencies like business days, which exclude weekends, can be challenging for time series forecasting methods.\nOur forecast method is equipped to handle this kind of irregular time series data, as long as you specify the frequency of the series. For example, in the case of business days, the frequency should be passed as ‘B’. Without this, the method might fail to automatically detect the frequency, especially when the timestamps are irregular.\nThe first step is to fetch your time series data. The data must include timestamps and the associated values. For instance, you might be working with stock prices, and your data could look something like the following. In this example we use OpenBB.\n\nfrom openbb_terminal.sdk import openbb\n\n\npltr_df = openbb.stocks.load('PLTR', start_date='2020-09-30').reset_index()\n\nLoading Daily data for PLTR with starting period 2020-09-30.\n\n\n\n\npltr_df.head()\n\n\n\n\n\n\n\n\ndate\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\nDividends\nStock Splits\n\n\n\n\n0\n2020-09-30\n10.00\n11.41\n9.11\n9.50\n9.50\n338584400\n0.0\n0.0\n\n\n1\n2020-10-01\n9.69\n10.10\n9.23\n9.46\n9.46\n124297600\n0.0\n0.0\n\n\n2\n2020-10-02\n9.06\n9.28\n8.94\n9.20\n9.20\n55018300\n0.0\n0.0\n\n\n3\n2020-10-05\n9.43\n9.49\n8.92\n9.03\n9.03\n36316900\n0.0\n0.0\n\n\n4\n2020-10-06\n9.04\n10.18\n8.90\n9.90\n9.90\n90864000\n0.0\n0.0\n\n\n\n\n\n\n\nLet’s see that this dataset has irregular timestamps. The dayofweek attribute from pandas’ DatetimeIndex returns the day of the week with Monday=0, Sunday=6. So, checking if dayofweek &gt; 4 is essentially checking if the date falls on a Saturday (5) or Sunday (6), which are typically non-business days (weekends).\n\n(pltr_df['date'].dt.dayofweek &gt; 4).sum()\n\n0\n\n\nAs we can see the timestamp is irregular. Let’s inspect the Close series.\n\npltr_df.set_index('date')['Close'].plot()\n\n&lt;Axes: xlabel='date'&gt;\n\n\n\n\n\nTo forecast this data, you can use our forecast method. Importantly, remember to specify the frequency of the data using the freq argument. In this case, it would be ‘B’ for business days. We also need to define the time_col to select the index of the series (by default is ds), and the target_col to forecast our target variable, in this case we will forecast Close:\n\nfcst_pltr_df = timegpt.forecast(\n    df=pltr_df, h=14, freq='B',\n    time_col='date', target_col='Close',\n)\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\nWARNING:__main__:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n\nfcst_pltr_df.head()\n\n\n\n\n\n\n\n\ndate\nTimeGPT\n\n\n\n\n0\n2023-08-28\n14.726294\n\n\n1\n2023-08-29\n14.632822\n\n\n2\n2023-08-30\n14.723761\n\n\n3\n2023-08-31\n14.722337\n\n\n4\n2023-09-01\n14.803411\n\n\n\n\n\n\n\nRemember, for business days, the frequency is ‘B’. For other frequencies, you can refer to the pandas offset aliases documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases.\nBy specifying the frequency, you’re helping the forecast method better understand the pattern in your data, resulting in more accurate and reliable forecasts.\nLet’s plot the forecasts generated by TimeGPT.\n\npd.concat([\n    pltr_df[['date', 'Close']].tail(90),\n    fcst_pltr_df\n]).set_index('date').plot()\n\n&lt;Axes: xlabel='date'&gt;\n\n\n\n\n\nYou can also add uncertainty quantification to your forecasts using the level argument:\n\nfcst_pltr_levels_df = timegpt.forecast(\n    df=pltr_df, h=42, freq='B',\n    time_col='date', target_col='Close',\n    add_history=True,\n    level=[40.66, 90]\n)\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\nWARNING:__main__:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:__main__:Calling Historical Forecast Endpoint...\n\n\n\nhistory_with_fcst_df = fcst_pltr_levels_df.merge(pltr_df.assign(date=lambda df: df['date'].astype(str)), how='left')\nax = history_with_fcst_df[['date', 'Close', 'TimeGPT']].set_index('date').plot(figsize=(20, 10))\nfor level, alpha in zip([40.66, 90], [0.4, 0.2]):\n    plt.fill_between(\n        history_with_fcst_df['date'], \n        history_with_fcst_df[f'TimeGPT-lo-{level}'], \n        history_with_fcst_df[f'TimeGPT-hi-{level}'], \n        color='orange', \n        alpha=alpha,\n        label=f'TimeGPT-level-{level}]'\n    )\nplt.legend()\nplt.show()\n\n\n\n\nIf you want to forecast another just change the target_col parameter. Let’s forecast Volume now:\n\nfcst_pltr_df = timegpt.forecast(\n    df=pltr_df, h=14, freq='B',\n    time_col='date', target_col='Volume',\n)\npd.concat([\n    pltr_df[['date', 'Volume']].tail(90),\n    fcst_pltr_df\n]).set_index('date').plot()\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\nWARNING:__main__:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n&lt;Axes: xlabel='date'&gt;\n\n\n\n\n\nBut what if we want to predict all the time series at once? We can do that reshaping our dataframe. Currently, the dataframe is in wide format (each series is a column), but we need to have them in long format (stacked one each other). We can do it with:\n\npltr_long_df = pd.melt(\n    pltr_df, \n    id_vars=['date'],\n    var_name='series_id'\n)\n\n\npltr_long_df.head()\n\n\n\n\n\n\n\n\ndate\nseries_id\nvalue\n\n\n\n\n0\n2020-09-30\nOpen\n10.00\n\n\n1\n2020-10-01\nOpen\n9.69\n\n\n2\n2020-10-02\nOpen\n9.06\n\n\n3\n2020-10-05\nOpen\n9.43\n\n\n4\n2020-10-06\nOpen\n9.04\n\n\n\n\n\n\n\nThen we just simply call the forecast method specifying the id_col parameter.\n\nfcst_pltr_long_df = timegpt.forecast(\n    df=pltr_long_df, h=14, freq='B',\n    id_col='series_id', time_col='date', target_col='value',\n)\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\nWARNING:__main__:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n\nfcst_pltr_long_df.head()\n\n\n\n\n\n\n\n\nseries_id\ndate\nTimeGPT\n\n\n\n\n0\nAdj Close\n2023-08-28\n14.726294\n\n\n1\nAdj Close\n2023-08-29\n14.632822\n\n\n2\nAdj Close\n2023-08-30\n14.723761\n\n\n3\nAdj Close\n2023-08-31\n14.722338\n\n\n4\nAdj Close\n2023-09-01\n14.803411\n\n\n\n\n\n\n\nThen we can forecast the Open series:\n\npd.concat([\n    pltr_long_df.query('series_id == \"Open\"').tail(90),\n    fcst_pltr_long_df.query('series_id == \"Open\"')\n]).set_index('date').plot()\n\n&lt;Axes: xlabel='date'&gt;\n\n\n\n\n\n\nAdding extra information\nIn time series forecasting, the variables that we predict are often influenced not just by their past values, but also by other factors or variables. These external variables, known as exogenous variables, can provide vital additional context that can significantly improve the accuracy of our forecasts. One such factor, and the focus of this tutorial, is the company’s revenue. Revenue figures can provide a key indicator of a company’s financial health and growth potential, both of which can heavily influence its stock price. That we can obtain from openbb.\n\nrevenue_pltr = openbb.stocks.fa.income('PLTR', quarterly=True, source='AlphaVantage').loc['totalRevenue'].reset_index()\n\n\nrevenue_pltr.tail()\n\n\n\n\n\n\n\n\nfiscalDateEnding\ntotalRevenue\n\n\n\n\n5\n2022-06-30\n473010000.0\n\n\n6\n2022-09-30\n477880000.0\n\n\n7\n2022-12-31\n508624000.0\n\n\n8\n2023-03-31\n525186000.0\n\n\n9\n2023-06-30\n533317000.0\n\n\n\n\n\n\n\nThe first thing we observe in our dataset is that we have information available only up until the end of the first quarter of 2023. Our data is represented in a quarterly frequency, and our goal is to leverage this information to forecast the daily stock prices for the next 14 days beyond this date.\nHowever, to accurately compute such a forecast that includes the revenue as an exogenous variable, we need to have an understanding of the future values of the revenue. This is critical because these future revenue values can significantly influence the stock price.\nSince we’re aiming to predict 14 daily stock prices, we only need to forecast the revenue for the upcoming quarter. This approach allows us to create a cohesive forecasting pipeline where the output of one forecast (revenue) is used as an input to another (stock price), thereby leveraging all available information for the most accurate predictions possible.\n\nfcst_pltr_revenue = timegpt.forecast(revenue_pltr, h=1, time_col='fiscalDateEnding', target_col='totalRevenue')\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\n\n\n\nfcst_pltr_revenue.head()\n\n\n\n\n\n\n\n\nfiscalDateEnding\nTimeGPT\n\n\n\n\n0\n2023-09-30\n547264448\n\n\n\n\n\n\n\nContinuing from where we left off, the next crucial step in our forecasting pipeline is to adjust the frequency of our data to match the stock prices’ frequency, which is represented on a business day basis. To accomplish this, we need to resample both the historical and future forecasted revenue data.\nWe can achieve this using the following code\n\nrevenue_pltr['fiscalDateEnding'] = pd.to_datetime(revenue_pltr['fiscalDateEnding'])\nrevenue_pltr = revenue_pltr.set_index('fiscalDateEnding').resample('B').ffill().reset_index()\n\nIMPORTANT NOTE: It’s crucial to highlight that in this process, we are assigning the same revenue value to all days within the given quarter. This simplification is necessary due to the disparity in granularity between quarterly revenue data and daily stock price data. However, it’s vital to treat this assumption with caution in practical applications. The impact of quarterly revenue figures on daily stock prices can vary significantly within the quarter based on a range of factors, including changing market expectations, other financial news, and events. In this tutorial, we use this assumption to illustrate the process of incorporating exogenous variables into our forecasting model, but in real-world scenarios, a more nuanced approach may be needed, depending on the available data and the specific use case.\nThen we can create the full historic dataset.\n\npltr_revenue_df = pltr_df.merge(revenue_pltr.rename(columns={'fiscalDateEnding': 'date'}))\n\n\npltr_revenue_df.head()\n\n\n\n\n\n\n\n\ndate\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\nDividends\nStock Splits\ntotalRevenue\n\n\n\n\n0\n2021-03-31\n22.500000\n23.850000\n22.379999\n23.290001\n23.290001\n61458500\n0.0\n0.0\n341234000.0\n\n\n1\n2021-04-01\n23.950001\n23.950001\n22.730000\n23.070000\n23.070000\n51788800\n0.0\n0.0\n341234000.0\n\n\n2\n2021-04-05\n23.780001\n24.450001\n23.340000\n23.440001\n23.440001\n65374300\n0.0\n0.0\n341234000.0\n\n\n3\n2021-04-06\n23.549999\n23.610001\n22.830000\n23.270000\n23.270000\n41933500\n0.0\n0.0\n341234000.0\n\n\n4\n2021-04-07\n23.000000\n23.549999\n22.809999\n22.900000\n22.900000\n32766200\n0.0\n0.0\n341234000.0\n\n\n\n\n\n\n\nTo calculate the dataframe of the future revenue:\n\nhorizon = 14\n\n\nimport numpy as np\n\n\nfuture_df = pd.DataFrame({\n    'date': pd.date_range(pltr_revenue_df['date'].iloc[-1], periods=horizon + 1, freq='B')[-horizon:],\n    'totalRevenue': np.repeat(fcst_pltr_revenue.iloc[0]['TimeGPT'], horizon)\n})\n\n\nfuture_df.head()\n\n\n\n\n\n\n\n\ndate\ntotalRevenue\n\n\n\n\n0\n2023-07-03\n547264448\n\n\n1\n2023-07-04\n547264448\n\n\n2\n2023-07-05\n547264448\n\n\n3\n2023-07-06\n547264448\n\n\n4\n2023-07-07\n547264448\n\n\n\n\n\n\n\nAnd then we can pass the future revenue in the forecast method using the X_df argument. Since the revenue is in the historic dataframe, that information will be used in the model.\n\nfcst_pltr_df = timegpt.forecast(\n    pltr_revenue_df, h=horizon, \n    freq='B',\n    time_col='date', \n    target_col='Close',\n    X_df=future_df,\n)\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\nWARNING:__main__:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n\npd.concat([\n    pltr_revenue_df[['date', 'Close']].tail(90),\n    fcst_pltr_df\n]).set_index('date').plot()\n\n&lt;Axes: xlabel='date'&gt;\n\n\n\n\n\nWe can also see the importance of the revenue:\n\ntimegpt.weights_x.plot.barh(x='features', y='weights')\n\n&lt;Axes: ylabel='features'&gt;\n\n\n\n\n\n\n\n\nCalendar variables\nWhen working with time series data, date features such as day, year, month, and others can have a significant impact on the target variable. For instance, retail sales might be influenced by the day of the week or the month of the year due to weekends or holiday shopping seasons.\nIn the provided code snippet, the date_features parameter is used to incorporate these temporal influences into the forecasting model.\n\nfcst_pltr_calendar_df = timegpt.forecast(\n    df=pltr_df.tail(2 * 14), h=14, freq='B',\n    time_col='date', target_col='Close',\n    date_features=True\n)\nfcst_pltr_calendar_df.head()\n\nINFO:__main__:Validating inputs...\nINFO:__main__:Preprocessing dataframes...\nINFO:__main__:Calling Forecast Endpoint...\nWARNING:__main__:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n\n\n\n\n\n\n\ndate\nTimeGPT\n\n\n\n\n0\n2023-08-28\n15.879999\n\n\n1\n2023-08-29\n16.511786\n\n\n2\n2023-08-30\n16.009749\n\n\n3\n2023-08-31\n17.660001\n\n\n4\n2023-09-01\n20.544631\n\n\n\n\n\n\n\n\npd.concat([\n    pltr_df[['date', 'Close']].tail(90),\n    fcst_pltr_calendar_df\n]).set_index('date').plot()\n\n&lt;Axes: xlabel='date'&gt;\n\n\n\n\n\nWe can also plot the importance of each of the date features:\n\ntimegpt.weights_x.plot.barh(x='features', y='weights', figsize=(10, 10))\n\n&lt;Axes: ylabel='features'&gt;\n\n\n\n\n\nHere’s a breakdown of how the date_features parameter works:\n\ndate_features (bool or list of str or callable): This parameter specifies which date attributes to consider.\n\nIf set to True, the model will automatically add the most common date features related to the frequency of the given dataframe (df). For a daily frequency, this could include features like day of the week, month, and year.\nIf provided a list of strings, it will consider those specific date attributes. For example, date_features=['weekday', 'month'] will only add the day of the week and month as features.\nIf provided a callable, it should be a function that takes dates as input and returns the desired feature. This gives flexibility in computing custom date features.\n\ndate_features_to_one_hot (bool or list of str): After determining the date features, one might want to one-hot encode them, especially if they are categorical in nature (like weekdays). One-hot encoding transforms these categorical features into a binary matrix, making them more suitable for many machine learning algorithms.\n\nIf date_features=True, then by default, all computed date features will be one-hot encoded.\nIf provided a list of strings, only those specific date features will be one-hot encoded.\n\n\nBy leveraging the date_features and date_features_to_one_hot parameters, one can efficiently incorporate the temporal effects of date attributes into their forecasting model, potentially enhancing its accuracy and interpretability."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NixtlaTS",
    "section": "",
    "text": "pip install nixtlats\nGive us a ⭐ on Github"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "NixtlaTS",
    "section": "",
    "text": "pip install nixtlats"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "NixtlaTS",
    "section": "How to use",
    "text": "How to use\nJust import the library, set your credentials, and start forecasting in two lines of code!\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short.csv')\n\nfrom nixtlats import TimeGPT\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\nfcst_df = timegpt.forecast(df, h=24, level=[80, 90])\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\n\n\n\nsf.plot(df, fcst_df, level=[80, 90], max_insample_length=24 * 5)"
  }
]